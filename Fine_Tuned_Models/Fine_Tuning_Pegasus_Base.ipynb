{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eeb1bb-ec45-4b91-9385-788f15c9244a",
   "metadata": {
    "id": "72eeb1bb-ec45-4b91-9385-788f15c9244a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07591351-15e2-4354-8bcf-78c1616834b9",
   "metadata": {
    "id": "07591351-15e2-4354-8bcf-78c1616834b9",
    "outputId": "3db42ad6-d154-4498-9d6d-9d3c4ab54128"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb99378-4af7-43f5-9e11-ba8186ff0775",
   "metadata": {
    "id": "dbb99378-4af7-43f5-9e11-ba8186ff0775"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d8b75-7b24-4bd2-b5e3-b3a8c965feee",
   "metadata": {
    "id": "b81d8b75-7b24-4bd2-b5e3-b3a8c965feee"
   },
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "class PegasusDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Adjusted for labels\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels['input_ids'])\n",
    "\n",
    "def prepare_data(model_name,\n",
    "                 train_texts, train_labels,\n",
    "                 val_texts, val_labels):\n",
    "    \"\"\"\n",
    "    Prepare input data for model fine-tuning\n",
    "    \"\"\"\n",
    "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def tokenize_data(texts, labels):\n",
    "        encodings = tokenizer(texts, max_length=10000, truncation=True, padding=True)  # Adjusted\n",
    "        decodings = tokenizer(labels, max_length=1000, truncation=True, padding=True)  # Adjusted\n",
    "        dataset_tokenized = PegasusDataset(encodings, decodings)\n",
    "        return dataset_tokenized\n",
    "\n",
    "    train_dataset = tokenize_data(train_texts, train_labels)\n",
    "    val_dataset = tokenize_data(val_texts, val_labels)\n",
    "\n",
    "    return train_dataset, val_dataset, tokenizer\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "def prepare_fine_tuning(model_name, tokenizer, train_dataset, val_dataset=None, freeze_encoder=False, output_dir='./results'):\n",
    "    \"\"\"\n",
    "    Prepare configurations and base model for fine-tuning\n",
    "    \"\"\"\n",
    "    torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "    if freeze_encoder:\n",
    "        for param in model.model.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,           # output directory\n",
    "        num_train_epochs=4,              # total number of training epochs\n",
    "        per_device_train_batch_size=1,   # batch size per device during training\n",
    "        per_device_eval_batch_size=1,    # batch size for evaluation                 # number of updates steps before checkpoint saves\n",
    "        fp16=True,\n",
    "        save_total_limit=1,              # limit the total amount of checkpoints\n",
    "        evaluation_strategy='epoch',\n",
    "        gradient_accumulation_steps=16,   # evaluation strategy\n",
    "        logging_dir='./logs',            # directory for logs\n",
    "        logging_steps=100,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,                         # the instantiated model to be trained\n",
    "        args=training_args,                  # training arguments\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,            # evaluation dataset\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    return trainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53446c7-fca4-486c-94cb-4873e0a8c3f8",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "29d99a6982f4496f8af94f7aba261fd4",
      "451b9adb1c444c0f8180c69776f2ec44",
      "ab4962c4db09438fa8a80c12209ca37f",
      "cfdcaf0e1d284d8a8debac68d78b4444",
      "5ec1bb328b674a309bff142091c73987"
     ]
    },
    "id": "d53446c7-fca4-486c-94cb-4873e0a8c3f8",
    "outputId": "5bc61e90-9dce-4dd4-8ac8-d6aa80531644"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # Load your datasets using pandas\n",
    "    train_data = pd.read_csv(\"train_data.csv\")  # Load training data\n",
    "    val_data = pd.read_csv(\"val_data.csv\")      # Load validation data\n",
    "\n",
    "    # Create Hugging Face Datasets from the DataFrames\n",
    "    train_dataset = Dataset.from_pandas(train_data)\n",
    "    val_dataset = Dataset.from_pandas(val_data)\n",
    "\n",
    "    # Extract the texts and labels\n",
    "    train_texts = train_dataset['Judgement']  # Adjust as needed\n",
    "    train_labels = train_dataset['Perspective-based Summary']\n",
    "\n",
    "    val_texts = val_dataset['Judgement']  # Adjust as needed\n",
    "    val_labels = val_dataset['Perspective-based Summary']\n",
    "\n",
    "    # Use Pegasus X-Large model as base for fine-tuning\n",
    "    model_name = 'google/pegasus-x-base'\n",
    "    train_dataset, val_dataset, tokenizer = prepare_data(model_name, train_texts, train_labels, val_texts, val_labels)\n",
    "    trainer = prepare_fine_tuning(model_name, tokenizer, train_dataset, val_dataset)\n",
    "    torch.cuda.empty_cache()\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the model and tokenizer\n",
    "    output_dir = './results__'  # Or any other directory you want to use\n",
    "    trainer.save_model(\"Pegasus_def\")  # Save the trained model\n",
    "    tokenizer.save_pretrained(\"Pegasus_def\")  # Save the tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3450f8-c1a8-4d7a-a6e1-0a8541ebd900",
   "metadata": {
    "id": "6e3450f8-c1a8-4d7a-a6e1-0a8541ebd900",
    "outputId": "0027c939-af0f-4403-abc3-9860f6f737b4"
   },
   "outputs": [],
   "source": [
    "!zip -r Pegasus_Def.zip Pegasus_Def"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
