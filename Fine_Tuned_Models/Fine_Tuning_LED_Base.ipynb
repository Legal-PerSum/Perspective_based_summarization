{"cells":[{"cell_type":"code","execution_count":null,"id":"658784d7-cfdb-424e-a2b2-76f0b6b8203d","metadata":{"id":"658784d7-cfdb-424e-a2b2-76f0b6b8203d","outputId":"d23b74b4-6f21-4fee-8a44-123a73dbc89f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.0)\n","Requirement already satisfied: openpyxl in /usr/lib/python3/dist-packages (3.0.3)\n","Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.23.4)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install pandas openpyxl"]},{"cell_type":"code","execution_count":null,"id":"2f05d557-a763-4d39-bf6f-79eea6e62618","metadata":{"id":"2f05d557-a763-4d39-bf6f-79eea6e62618","outputId":"779cd33b-4ebe-4f86-c9d9-67911fa46b74"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.28.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.23.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.1.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"id":"cb9a1a21-b218-4a78-9fbf-eeed6f5da249","metadata":{"id":"cb9a1a21-b218-4a78-9fbf-eeed6f5da249"},"outputs":[],"source":["import numpy as np\n","from transformers import AutoTokenizer"]},{"cell_type":"code","execution_count":null,"id":"8620b18c-5dd5-44ba-8165-1d9b4b23eb39","metadata":{"colab":{"referenced_widgets":["c686e979c6ac4bbdad2f79e643f32654","c8228fd2630a4b18a23af2f29e837884","74de4a2e85c444e38983ab29789d3e6c","fcb39c81d1b64834a54c291cf8d3f027","6aeae02a6ae247e8887526067f748c8e"]},"id":"8620b18c-5dd5-44ba-8165-1d9b4b23eb39","outputId":"d725d52b-fa14-4c54-afd9-e8fab4bf4114"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c686e979c6ac4bbdad2f79e643f32654","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8228fd2630a4b18a23af2f29e837884","version_major":2,"version_minor":0},"text/plain":["Downloading config.json:   0%|          | 0.00/1.07k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74de4a2e85c444e38983ab29789d3e6c","version_major":2,"version_minor":0},"text/plain":["Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fcb39c81d1b64834a54c291cf8d3f027","version_major":2,"version_minor":0},"text/plain":["Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6aeae02a6ae247e8887526067f748c8e","version_major":2,"version_minor":0},"text/plain":["Downloading special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")"]},{"cell_type":"code","execution_count":null,"id":"7313579b-4e4a-4799-833d-afdf4b4341d0","metadata":{"id":"7313579b-4e4a-4799-833d-afdf4b4341d0"},"outputs":[],"source":["max_input_length = 16384\n","max_output_length = 750\n","batch_size = 2"]},{"cell_type":"code","execution_count":null,"id":"e7fc4252-328d-442a-ad9e-4f62c1783836","metadata":{"collapsed":true,"id":"e7fc4252-328d-442a-ad9e-4f62c1783836"},"outputs":[],"source":["import pandas as pd\n","from datasets import Dataset\n","\n","# Load the CSV file using pandas\n","train_excel_file = pd.read_csv('train_data.csv')\n","val_excel_file = pd.read_csv('val_data.csv')\n","\n","# Convert the pandas DataFrame to a datasets Dataset\n","train_dataset = Dataset.from_pandas(train_excel_file)\n","val_dataset = Dataset.from_pandas(val_excel_file)"]},{"cell_type":"code","execution_count":null,"id":"4c6e8bfb-45ba-43c2-b421-79f2ab1c8c15","metadata":{"id":"4c6e8bfb-45ba-43c2-b421-79f2ab1c8c15"},"outputs":[],"source":["def process_data_to_model_inputs(batch):\n","    # tokenize the inputs and labels\n","    inputs = tokenizer(\n","        batch[\"Judgement\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=max_input_length,\n","        return_tensors=\"pt\",\n","    )\n","    outputs = tokenizer(\n","        batch[\"Perspective-based Summary\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=max_output_length,\n","    )\n","\n","    batch[\"input_ids\"] = inputs.input_ids.tolist()  # Convert to list\n","    batch[\"attention_mask\"] = inputs.attention_mask.tolist()\n","\n","    # create 0 global_attention_mask lists\n","    batch[\"global_attention_mask\"] = [\n","        [0 for _ in range(len(batch[\"input_ids\"][0]))]\n","    ] * len(batch[\"input_ids\"])\n","\n","\n","    # since above lists are references, the following line changes the 0 index for all samples\n","    batch[\"global_attention_mask\"][0][0] = 1\n","    batch[\"labels\"] = outputs.input_ids\n","\n","    # We have to make sure that the PAD token is ignored\n","    batch[\"labels\"] = [  # Convert PyTorch tensor to numpy array\n","        np.array([-100 if token == tokenizer.pad_token_id else token for token in labels])\n","        for labels in batch[\"labels\"]\n","    ]\n","\n","    return batch"]},{"cell_type":"code","execution_count":null,"id":"84b4a3c5-3ab6-4332-bc6e-27a509beff28","metadata":{"colab":{"referenced_widgets":["5856314555e6481bae03a1c452b4137f"]},"id":"84b4a3c5-3ab6-4332-bc6e-27a509beff28","outputId":"84ac15e0-7c88-460d-9721-9443a324346e"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5856314555e6481bae03a1c452b4137f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1917 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_dataset = train_dataset.map(\n","    process_data_to_model_inputs,\n","    batched=True,\n","    batch_size=batch_size,\n","    remove_columns=[\"Judgement\", \"Perspective-based Summary\"],\n",")"]},{"cell_type":"code","execution_count":null,"id":"3e278ae6-f650-4bf6-8100-4ece3ab049f8","metadata":{"colab":{"referenced_widgets":["3f3489bb79d04a9b8f023d16effc2308"]},"id":"3e278ae6-f650-4bf6-8100-4ece3ab049f8","outputId":"607e4d83-31bb-4d4e-80c9-8a7665e41335"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f3489bb79d04a9b8f023d16effc2308","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/50 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["val_dataset = val_dataset.map(\n","    process_data_to_model_inputs,\n","    batched=True,\n","    batch_size=batch_size,\n","    remove_columns=[\"Judgement\", \"Perspective-based Summary\"],\n",")"]},{"cell_type":"code","execution_count":null,"id":"3231ac82-3db6-4c95-ac63-883b7ac8f800","metadata":{"id":"3231ac82-3db6-4c95-ac63-883b7ac8f800","outputId":"1635541a-e21d-43ae-9b52-61775a0c58e8"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>judgement</th>\n","      <th>summary</th>\n","      <th>prosecutor_pov</th>\n","      <th>defense_pov</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>100</td>\n","      <td>100</td>\n","      <td>100</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>100</td>\n","      <td>100</td>\n","      <td>100</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>iminal Appeals No,%.\\n79 and 89 of 1959.\\nAppe...</td>\n","      <td>\\n  \"prosecution\": \"From the perspective of th...</td>\n","      <td>From the perspective of the prosecution attorn...</td>\n","      <td>From the defense attorney's perspective, this ...</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                judgement  \\\n","count                                                 100   \n","unique                                                100   \n","top     iminal Appeals No,%.\\n79 and 89 of 1959.\\nAppe...   \n","freq                                                    1   \n","\n","                                                  summary  \\\n","count                                                 100   \n","unique                                                100   \n","top     \\n  \"prosecution\": \"From the perspective of th...   \n","freq                                                    1   \n","\n","                                           prosecutor_pov  \\\n","count                                                 100   \n","unique                                                100   \n","top     From the perspective of the prosecution attorn...   \n","freq                                                    1   \n","\n","                                              defense_pov  \n","count                                                 100  \n","unique                                                100  \n","top     From the defense attorney's perspective, this ...  \n","freq                                                    1  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train_excel_file.describe()\n","val_excel_file.describe()"]},{"cell_type":"code","execution_count":null,"id":"813c8c01-d62d-4fdd-a574-54a652c190dd","metadata":{"id":"813c8c01-d62d-4fdd-a574-54a652c190dd"},"outputs":[],"source":["train_dataset.set_format(\n","    type=\"torch\",\n","    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",")"]},{"cell_type":"code","execution_count":null,"id":"3cfd7c92-6522-4a98-b49d-a8a874086c48","metadata":{"id":"3cfd7c92-6522-4a98-b49d-a8a874086c48"},"outputs":[],"source":["val_dataset.set_format(\n","    type=\"torch\",\n","    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",")"]},{"cell_type":"code","execution_count":null,"id":"dc8fbddd-a847-41c4-b200-df40527d941c","metadata":{"id":"dc8fbddd-a847-41c4-b200-df40527d941c"},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM"]},{"cell_type":"code","execution_count":null,"id":"6e949b74-c2d9-4460-b25e-ddcbfbd4388b","metadata":{"colab":{"referenced_widgets":["d417b68491bc4f48800b9518573cb282"]},"id":"6e949b74-c2d9-4460-b25e-ddcbfbd4388b","outputId":"87db9f2e-3108-44b1-a9af-1f28d7108257"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d417b68491bc4f48800b9518573cb282","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/618M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True, use_cache=False)"]},{"cell_type":"code","execution_count":null,"id":"b5e1c457-8e4d-4752-ac1f-deb9cd4dfc35","metadata":{"id":"b5e1c457-8e4d-4752-ac1f-deb9cd4dfc35"},"outputs":[],"source":["# set generate hyperparameters\n","model.config.num_beams = 2\n","model.config.max_length = max_output_length\n","model.config.min_length = 300\n","model.config.length_penalty = 2.0\n","model.config.early_stopping = True\n","model.config.no_repeat_ngram_size = 4"]},{"cell_type":"code","execution_count":null,"id":"29e2498f-03e1-4402-97e2-690e079c6d0f","metadata":{"id":"29e2498f-03e1-4402-97e2-690e079c6d0f"},"outputs":[],"source":["from transformers import Seq2SeqTrainingArguments"]},{"cell_type":"code","execution_count":null,"id":"f3410a48-add8-4b0c-992c-92839910a182","metadata":{"id":"f3410a48-add8-4b0c-992c-92839910a182"},"outputs":[],"source":["# enable fp16 apex training\n","training_args = Seq2SeqTrainingArguments(\n","    predict_with_generate=True,\n","    evaluation_strategy=\"steps\",\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    fp16=True,\n","    output_dir=\"Untitled Folder\",\n","    logging_steps=50,\n","    save_steps=150,\n","    save_total_limit=1,\n","    gradient_accumulation_steps=32,\n","    num_train_epochs=3,\n","    warmup_steps=200,\n",")"]},{"cell_type":"code","execution_count":null,"id":"a883256c-f9ad-48aa-b66e-899fd4417cdd","metadata":{"id":"a883256c-f9ad-48aa-b66e-899fd4417cdd"},"outputs":[],"source":["from transformers import Seq2SeqTrainer"]},{"cell_type":"code","execution_count":null,"id":"2e637977-e287-48ec-95b7-960eefdde437","metadata":{"id":"2e637977-e287-48ec-95b7-960eefdde437","outputId":"93dec87c-a268-4b99-b604-0ec5b450e2cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stderr","output_type":"stream","text":["Using cuda_amp half precision backend\n"]}],"source":["trainer = Seq2SeqTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    args=training_args,\n","    #compute_metrics=compute_metrics,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset\n",")"]},{"cell_type":"code","execution_count":null,"id":"182a5775-f138-429e-bc7f-660dfcf86e01","metadata":{"id":"182a5775-f138-429e-bc7f-660dfcf86e01","outputId":"cb498ad8-b92d-41de-e0b6-fc5ff9176881"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the training set don't have a corresponding argument in `LEDForConditionalGeneration.forward` and have been ignored: defense_pov, summary. If defense_pov, summary are not expected by `LEDForConditionalGeneration.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 3833\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 32\n","  Total optimization steps = 177\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdin","output_type":"stream","text":["  ········\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"data":{"text/html":["wandb version 0.18.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/notebooks/wandb/run-20241024_110634-2apnim5t</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/legalts/huggingface/runs/2apnim5t\" target=\"_blank\">Untitled Folder</a></strong> to <a href=\"https://wandb.ai/legalts/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='177' max='177' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [177/177 3:57:20, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>2.415200</td>\n","      <td>1.754704</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.711000</td>\n","      <td>1.548222</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.549900</td>\n","      <td>1.464082</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set don't have a corresponding argument in `LEDForConditionalGeneration.forward` and have been ignored: defense_pov, summary. If defense_pov, summary are not expected by `LEDForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 100\n","  Batch size = 2\n","wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n","wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n","wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n","wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n","The following columns in the evaluation set don't have a corresponding argument in `LEDForConditionalGeneration.forward` and have been ignored: defense_pov, summary. If defense_pov, summary are not expected by `LEDForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 100\n","  Batch size = 2\n","The following columns in the evaluation set don't have a corresponding argument in `LEDForConditionalGeneration.forward` and have been ignored: defense_pov, summary. If defense_pov, summary are not expected by `LEDForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 100\n","  Batch size = 2\n","Saving model checkpoint to Untitled Folder/checkpoint-150\n","Configuration saved in Untitled Folder/checkpoint-150/config.json\n","Model weights saved in Untitled Folder/checkpoint-150/pytorch_model.bin\n","tokenizer config file saved in Untitled Folder/checkpoint-150/tokenizer_config.json\n","Special tokens file saved in Untitled Folder/checkpoint-150/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=177, training_loss=1.8248963652357544, metrics={'train_runtime': 14343.5337, 'train_samples_per_second': 0.802, 'train_steps_per_second': 0.012, 'total_flos': 1.2358297487985869e+17, 'train_loss': 1.8248963652357544, 'epoch': 2.98})"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"c0122dac-8f9a-4e4c-8509-e3c1a65db7e2","metadata":{"id":"c0122dac-8f9a-4e4c-8509-e3c1a65db7e2","outputId":"1e14a6d3-f774-4094-e75f-2535bf736377"},"outputs":[{"name":"stderr","output_type":"stream","text":["Configuration saved in legal-led-pro-3/config.json\n","Model weights saved in legal-led-pro-3/pytorch_model.bin\n"]}],"source":["model.save_pretrained('legal-led-pro-3')"]},{"cell_type":"code","execution_count":null,"id":"5e7357cd-cb4d-452b-8ef1-0ea8220dd0fa","metadata":{"id":"5e7357cd-cb4d-452b-8ef1-0ea8220dd0fa","outputId":"7ff3884c-5d7b-4f72-81af-e4324333fbd2"},"outputs":[{"name":"stderr","output_type":"stream","text":["tokenizer config file saved in legal-led-pro-3/tokenizer_config.json\n","Special tokens file saved in legal-led-pro-3/special_tokens_map.json\n"]},{"data":{"text/plain":["('legal-led-pro-3/tokenizer_config.json',\n"," 'legal-led-pro-3/special_tokens_map.json',\n"," 'legal-led-pro-3/vocab.json',\n"," 'legal-led-pro-3/merges.txt',\n"," 'legal-led-pro-3/added_tokens.json',\n"," 'legal-led-pro-3/tokenizer.json')"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.save_pretrained('legal-led-pro-3')"]},{"cell_type":"code","execution_count":null,"id":"f0e728e0-e239-4bf2-a9c0-1950559feac7","metadata":{"id":"f0e728e0-e239-4bf2-a9c0-1950559feac7","outputId":"74028493-1ee8-4f9f-e69a-c9d31e5dd4f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","  adding: legal-led-pro-3/ (stored 0%)\n","  adding: legal-led-pro-3/pytorch_model.bin (deflated 9%)\n","  adding: legal-led-pro-3/vocab.json (deflated 59%)\n","  adding: legal-led-pro-3/tokenizer.json (deflated 72%)\n","  adding: legal-led-pro-3/config.json (deflated 60%)\n","  adding: legal-led-pro-3/tokenizer_config.json (deflated 74%)\n","  adding: legal-led-pro-3/special_tokens_map.json (deflated 85%)\n","  adding: legal-led-pro-3/merges.txt (deflated 53%)\n"]}],"source":["!zip -r legal-led-pro-3.zip legal-led-pro-3"]},{"cell_type":"code","execution_count":null,"id":"ae2e7515-7f89-4345-a188-705ec3f6edca","metadata":{"id":"ae2e7515-7f89-4345-a188-705ec3f6edca"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}