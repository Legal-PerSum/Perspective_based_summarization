{"cells":[{"cell_type":"code","execution_count":null,"id":"72eeb1bb-ec45-4b91-9385-788f15c9244a","metadata":{"id":"72eeb1bb-ec45-4b91-9385-788f15c9244a"},"outputs":[],"source":["import os\n","os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\""]},{"cell_type":"code","execution_count":null,"id":"07591351-15e2-4354-8bcf-78c1616834b9","metadata":{"id":"07591351-15e2-4354-8bcf-78c1616834b9","outputId":"3db42ad6-d154-4498-9d6d-9d3c4ab54128"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Oct 31 19:25:00 2024       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA RTX A6000    Off  | 00000000:00:05.0 Off |                  Off |\n","| 30%   38C    P8    25W / 300W |      1MiB / 49140MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"id":"dbb99378-4af7-43f5-9e11-ba8186ff0775","metadata":{"id":"dbb99378-4af7-43f5-9e11-ba8186ff0775"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv(\"train_data.csv\")"]},{"cell_type":"code","execution_count":null,"id":"b81d8b75-7b24-4bd2-b5e3-b3a8c965feee","metadata":{"id":"b81d8b75-7b24-4bd2-b5e3-b3a8c965feee"},"outputs":[],"source":["from transformers import PegasusForConditionalGeneration, PegasusTokenizer, Trainer, TrainingArguments\n","import torch\n","import pandas as pd\n","from datasets import Dataset\n","\n","class PegasusDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # Adjusted for labels\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels['input_ids'])\n","\n","def prepare_data(model_name,\n","                 train_texts, train_labels,\n","                 val_texts, val_labels):\n","    \"\"\"\n","    Prepare input data for model fine-tuning\n","    \"\"\"\n","    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n","\n","    def tokenize_data(texts, labels):\n","        encodings = tokenizer(texts, max_length=10000, truncation=True, padding=True)  # Adjusted\n","        decodings = tokenizer(labels, max_length=1000, truncation=True, padding=True)  # Adjusted\n","        dataset_tokenized = PegasusDataset(encodings, decodings)\n","        return dataset_tokenized\n","\n","    train_dataset = tokenize_data(train_texts, train_labels)\n","    val_dataset = tokenize_data(val_texts, val_labels)\n","\n","    return train_dataset, val_dataset, tokenizer\n","import torch\n","torch.cuda.empty_cache()\n","def prepare_fine_tuning(model_name, tokenizer, train_dataset, val_dataset=None, freeze_encoder=False, output_dir='./results'):\n","    \"\"\"\n","    Prepare configurations and base model for fine-tuning\n","    \"\"\"\n","    torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n","\n","    if freeze_encoder:\n","        for param in model.model.encoder.parameters():\n","            param.requires_grad = False\n","\n","    training_args = TrainingArguments(\n","        output_dir=output_dir,           # output directory\n","        num_train_epochs=4,              # total number of training epochs\n","        per_device_train_batch_size=1,   # batch size per device during training\n","        per_device_eval_batch_size=1,    # batch size for evaluation                 # number of updates steps before checkpoint saves\n","        fp16=True,\n","        save_total_limit=1,              # limit the total amount of checkpoints\n","        evaluation_strategy='epoch',\n","        gradient_accumulation_steps=16,   # evaluation strategy\n","        logging_dir='./logs',            # directory for logs\n","        logging_steps=100,\n","    )\n","\n","    trainer = Trainer(\n","        model=model,                         # the instantiated model to be trained\n","        args=training_args,                  # training arguments\n","        train_dataset=train_dataset,\n","        eval_dataset=val_dataset,            # evaluation dataset\n","        tokenizer=tokenizer\n","    )\n","\n","    return trainer\n","\n"]},{"cell_type":"code","execution_count":null,"id":"d53446c7-fca4-486c-94cb-4873e0a8c3f8","metadata":{"colab":{"referenced_widgets":["29d99a6982f4496f8af94f7aba261fd4","451b9adb1c444c0f8180c69776f2ec44","ab4962c4db09438fa8a80c12209ca37f","cfdcaf0e1d284d8a8debac68d78b4444","5ec1bb328b674a309bff142091c73987"]},"id":"d53446c7-fca4-486c-94cb-4873e0a8c3f8","outputId":"5bc61e90-9dce-4dd4-8ac8-d6aa80531644"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29d99a6982f4496f8af94f7aba261fd4","version_major":2,"version_minor":0},"text/plain":["Downloading spiece.model:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"451b9adb1c444c0f8180c69776f2ec44","version_major":2,"version_minor":0},"text/plain":["Downloading special_tokens_map.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab4962c4db09438fa8a80c12209ca37f","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cfdcaf0e1d284d8a8debac68d78b4444","version_major":2,"version_minor":0},"text/plain":["Downloading config.json:   0%|          | 0.00/1.45k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You are using a model of type pegasus_x to instantiate a model of type pegasus. This is not supported for all configurations of models and can yield errors.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ec1bb328b674a309bff142091c73987","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/1.01G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at google/pegasus-x-base were not used when initializing PegasusForConditionalGeneration: ['model.encoder.layers.5.global_self_attn_layer_norm.bias', 'model.encoder.layers.4.global_self_attn_layer_norm.bias', 'model.encoder.embed_global.weight', 'model.encoder.layers.8.global_self_attn_layer_norm.bias', 'model.encoder.layers.2.global_self_attn_layer_norm.weight', 'model.encoder.layers.4.global_self_attn_layer_norm.weight', 'model.encoder.layers.9.global_self_attn_layer_norm.bias', 'model.encoder.layers.7.global_self_attn_layer_norm.bias', 'model.encoder.layers.11.global_self_attn_layer_norm.weight', 'model.encoder.layers.3.global_self_attn_layer_norm.bias', 'model.encoder.layers.1.global_self_attn_layer_norm.weight', 'model.encoder.layers.3.global_self_attn_layer_norm.weight', 'model.encoder.layers.8.global_self_attn_layer_norm.weight', 'model.encoder.layers.0.global_self_attn_layer_norm.weight', 'model.encoder.layers.6.global_self_attn_layer_norm.bias', 'model.encoder.layers.11.global_self_attn_layer_norm.bias', 'model.encoder.layers.10.global_self_attn_layer_norm.bias', 'model.encoder.layers.2.global_self_attn_layer_norm.bias', 'model.encoder.layers.9.global_self_attn_layer_norm.weight', 'model.encoder.layers.10.global_self_attn_layer_norm.weight', 'model.encoder.layers.7.global_self_attn_layer_norm.weight', 'model.encoder.layers.5.global_self_attn_layer_norm.weight', 'model.encoder.layers.6.global_self_attn_layer_norm.weight', 'model.encoder.layers.0.global_self_attn_layer_norm.bias', 'model.encoder.layers.1.global_self_attn_layer_norm.bias']\n","- This IS expected if you are initializing PegasusForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing PegasusForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-x-base and are newly initialized: ['model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.7.encoder_attn.out_proj.bias', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.9.encoder_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.encoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.11.encoder_attn.v_proj.bias', 'model.decoder.layers.8.encoder_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.0.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.6.encoder_attn.q_proj.bias', 'model.decoder.layers.0.encoder_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.11.encoder_attn.k_proj.bias', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.10.encoder_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.7.encoder_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.7.encoder_attn.v_proj.bias', 'model.decoder.layers.8.encoder_attn.out_proj.bias', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.9.encoder_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.0.encoder_attn.out_proj.bias', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.0.encoder_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.10.encoder_attn.out_proj.bias', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.11.encoder_attn.q_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.encoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.6.encoder_attn.v_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.9.encoder_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.10.encoder_attn.v_proj.bias', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn.out_proj.bias', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.10.encoder_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.decoder.layers.9.encoder_attn.out_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.11.encoder_attn.out_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.7.encoder_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.0.encoder_attn.k_proj.bias', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.8.encoder_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.8.encoder_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn.k_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using cuda_amp half precision backend\n","/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 3833\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 1\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 16\n","  Total optimization steps = 956\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.18.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/notebooks/wandb/run-20241031_193144-2ev9hu7p</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/legalts/huggingface/runs/2ev9hu7p\" target=\"_blank\">./results</a></strong> to <a href=\"https://wandb.ai/legalts/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='956' max='956' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [956/956 3:10:09, Epoch 3/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.411600</td>\n","      <td>1.323182</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>1.171700</td>\n","      <td>1.250078</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.106100</td>\n","      <td>1.224673</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.087700</td>\n","      <td>1.217358</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 100\n","  Batch size = 1\n","***** Running Evaluation *****\n","  Num examples = 100\n","  Batch size = 1\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in ./results/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 100\n","  Batch size = 1\n","***** Running Evaluation *****\n","  Num examples = 100\n","  Batch size = 1\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Saving model checkpoint to Pegasus_Def\n","Configuration saved in Pegasus_Def/config.json\n","Model weights saved in Pegasus_Def/pytorch_model.bin\n","tokenizer config file saved in Pegasus_Def/tokenizer_config.json\n","Special tokens file saved in Pegasus_Def/special_tokens_map.json\n","tokenizer config file saved in Pegasus_Def/tokenizer_config.json\n","Special tokens file saved in Pegasus_Def/special_tokens_map.json\n"]}],"source":["\n","import torch\n","torch.cuda.empty_cache()\n","\n","if __name__=='__main__':\n","    # Load your datasets using pandas\n","    train_data = pd.read_csv(\"train_data.csv\")  # Load training data\n","    val_data = pd.read_csv(\"val_data.csv\")      # Load validation data\n","\n","    # Create Hugging Face Datasets from the DataFrames\n","    train_dataset = Dataset.from_pandas(train_data)\n","    val_dataset = Dataset.from_pandas(val_data)\n","\n","    # Extract the texts and labels\n","    train_texts = train_dataset['Judgement']  # Adjust as needed\n","    train_labels = train_dataset['Perspective-based Summary']\n","\n","    val_texts = val_dataset['Judgement']  # Adjust as needed\n","    val_labels = val_dataset['Perspective-based Summary']\n","\n","    # Use Pegasus X-Large model as base for fine-tuning\n","    model_name = 'google/pegasus-x-base'\n","    train_dataset, val_dataset, tokenizer = prepare_data(model_name, train_texts, train_labels, val_texts, val_labels)\n","    trainer = prepare_fine_tuning(model_name, tokenizer, train_dataset, val_dataset)\n","    torch.cuda.empty_cache()\n","    trainer.train()\n","\n","    # Save the model and tokenizer\n","    output_dir = './results__'  # Or any other directory you want to use\n","    trainer.save_model(\"Pegasus_def\")  # Save the trained model\n","    tokenizer.save_pretrained(\"Pegasus_def\")  # Save the tokenizer\n"]},{"cell_type":"code","execution_count":null,"id":"6e3450f8-c1a8-4d7a-a6e1-0a8541ebd900","metadata":{"id":"6e3450f8-c1a8-4d7a-a6e1-0a8541ebd900","outputId":"0027c939-af0f-4403-abc3-9860f6f737b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["updating: Pegasus_Def/ (stored 0%)\n","updating: Pegasus_Def/pytorch_model.bin (deflated 7%)\n","updating: Pegasus_Def/training_args.bin (deflated 49%)\n","updating: Pegasus_Def/config.json (deflated 60%)\n","updating: Pegasus_Def/tokenizer_config.json (deflated 77%)\n","updating: Pegasus_Def/special_tokens_map.json (deflated 82%)\n","updating: Pegasus_Def/spiece.model (deflated 50%)\n"]}],"source":["!zip -r Pegasus_Def.zip Pegasus_Def"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}